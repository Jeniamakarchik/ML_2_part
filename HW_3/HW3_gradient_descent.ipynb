{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW3. Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разобъем выборку на тренировочную и тестовую. Разбиение будем проводить сбалансированное, чтобы сохранялось процентное соотношение классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('Iris-setosa', 'Iris-versicolor', 'Iris-virginica')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3            4\n",
       "0  5.1  3.5  1.4  0.2  Iris-setosa\n",
       "1  4.9  3.0  1.4  0.2  Iris-setosa\n",
       "2  4.7  3.2  1.3  0.2  Iris-setosa\n",
       "3  4.6  3.1  1.5  0.2  Iris-setosa\n",
       "4  5.0  3.6  1.4  0.2  Iris-setosa"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('iris.data', header=None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((135, 5), (15, 5))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = train_test_split(data, train_size=0.9, random_state=42, stratify=data[4])\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[[0, 1, 2, 3]]\n",
    "y_train = train[4]\n",
    "X_test = test[[0, 1, 2, 3]]\n",
    "y_test = test[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "train_scaled = pd.DataFrame(scaler.transform(X_train))\n",
    "train_scaled[4] = y_train.reset_index(drop=True)\n",
    "test_scaled = pd.DataFrame(scaler.transform(X_test))\n",
    "test_scaled[4] = y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.937066</td>\n",
       "      <td>-0.348086</td>\n",
       "      <td>0.484926</td>\n",
       "      <td>0.124931</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.328874</td>\n",
       "      <td>-1.029122</td>\n",
       "      <td>1.056673</td>\n",
       "      <td>0.255674</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.815428</td>\n",
       "      <td>-0.121073</td>\n",
       "      <td>0.827974</td>\n",
       "      <td>1.040127</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.279318</td>\n",
       "      <td>-1.256135</td>\n",
       "      <td>0.084703</td>\n",
       "      <td>-0.136553</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.788535</td>\n",
       "      <td>-0.348086</td>\n",
       "      <td>1.456896</td>\n",
       "      <td>0.778642</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.738979</td>\n",
       "      <td>0.332951</td>\n",
       "      <td>-1.401839</td>\n",
       "      <td>-1.313232</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.738979</td>\n",
       "      <td>-0.121073</td>\n",
       "      <td>-1.401839</td>\n",
       "      <td>-1.313232</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.009148</td>\n",
       "      <td>0.786976</td>\n",
       "      <td>-1.287490</td>\n",
       "      <td>-1.313232</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.693789</td>\n",
       "      <td>-0.575098</td>\n",
       "      <td>1.056673</td>\n",
       "      <td>1.301611</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.937066</td>\n",
       "      <td>-0.121073</td>\n",
       "      <td>0.370577</td>\n",
       "      <td>0.255674</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.036041</td>\n",
       "      <td>2.149050</td>\n",
       "      <td>-1.459014</td>\n",
       "      <td>-1.313232</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.815428</td>\n",
       "      <td>-0.121073</td>\n",
       "      <td>0.999499</td>\n",
       "      <td>0.778642</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.693789</td>\n",
       "      <td>0.332951</td>\n",
       "      <td>0.427751</td>\n",
       "      <td>0.386416</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.058705</td>\n",
       "      <td>-0.121073</td>\n",
       "      <td>0.713625</td>\n",
       "      <td>0.647900</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.765871</td>\n",
       "      <td>0.786976</td>\n",
       "      <td>-1.344664</td>\n",
       "      <td>-1.313232</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3                4\n",
       "0   0.937066 -0.348086  0.484926  0.124931  Iris-versicolor\n",
       "1   0.328874 -1.029122  1.056673  0.255674   Iris-virginica\n",
       "2   0.815428 -0.121073  0.827974  1.040127   Iris-virginica\n",
       "3  -0.279318 -1.256135  0.084703 -0.136553  Iris-versicolor\n",
       "4   1.788535 -0.348086  1.456896  0.778642   Iris-virginica\n",
       "5  -1.738979  0.332951 -1.401839 -1.313232      Iris-setosa\n",
       "6  -1.738979 -0.121073 -1.401839 -1.313232      Iris-setosa\n",
       "7  -1.009148  0.786976 -1.287490 -1.313232      Iris-setosa\n",
       "8   0.693789 -0.575098  1.056673  1.301611   Iris-virginica\n",
       "9   0.937066 -0.121073  0.370577  0.255674  Iris-versicolor\n",
       "10 -0.036041  2.149050 -1.459014 -1.313232      Iris-setosa\n",
       "11  0.815428 -0.121073  0.999499  0.778642   Iris-virginica\n",
       "12  0.693789  0.332951  0.427751  0.386416  Iris-versicolor\n",
       "13  1.058705 -0.121073  0.713625  0.647900  Iris-versicolor\n",
       "14 -0.765871  0.786976 -1.344664 -1.313232      Iris-setosa"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled.to_csv('train.csv', header=False, index=False)\n",
    "test_scaled.to_csv('test.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv', header=None)\n",
    "test_data = pd.read_csv('test.csv', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 - 3.\n",
    "Обучите модель логистической регресси с помощью SGD и batch gradient descent. Подберите нужные параметры по сетке. Сравните полученные решения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем свой класс-классификатор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GDClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, type_='stochastic', learning_rate=0.01, n_iter=1000, alpha=0.01):\n",
    "        self.type_ = type_\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iter = n_iter\n",
    "        self.alpha = alpha\n",
    "\n",
    "        self.weights = None\n",
    "        self.coeffs_ = None\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid(x):\n",
    "        return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_gradient(x, y, w):\n",
    "        grad = np.dot(x.T, GDClassifier.sigmoid(x.dot(w)) - y)\n",
    "        return grad if len(x.shape) == 1 else grad / len(x)\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        x, y = X_train, y_train\n",
    "        n_obs = x.shape[0]\n",
    "        n_features = x.shape[1]\n",
    "\n",
    "        self.weights = np.zeros((self.n_iter, n_features))\n",
    "\n",
    "        for k in range(self.n_iter - 1):\n",
    "            if self.type_ == 'stochastic':\n",
    "                ind = randint(0, n_obs - 1)\n",
    "                x, y = X_train[ind, :], y_train[ind]\n",
    "\n",
    "            w = self.weights[k]\n",
    "            grad = self.compute_gradient(x, y, w) + self.alpha*w\n",
    "\n",
    "            u = -self.learning_rate*grad\n",
    "            self.weights[k+1] = self.weights[k] + u\n",
    "        \n",
    "        half = self.n_iter//2\n",
    "        self.coeffs_ = self.weights[half:].mean(axis=0)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.sigmoid(X.dot(self.coeffs_)) >= 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим данные: выберем константный столбец и выделим наш целевой класс в данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(X, y, class_name):\n",
    "    X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "    y = (y == class_name)\n",
    "    return X.astype(float), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зададим данные для перебора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'learning_rate': [0.1, 0.05, 0.01, 0.005, 0.001],\n",
    "    'n_iter': [100, 200, 500, 750, 1000, 2500, 5000],\n",
    "    'alpha': [0.01, 0.001, 0.0001, 0.0]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем эксперименты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** ***** ***** *****\n",
      "Target class: Iris-setosa\n",
      "Method: batch\n",
      "Best classifier: GDClassifier(alpha=0.01, learning_rate=0.1, n_iter=100, type_='batch')\n",
      "Best CV score: 1.0\n",
      "Test score: 1.0\n",
      "***** ***** ***** *****\n",
      "\n",
      "***** ***** ***** *****\n",
      "Target class: Iris-versicolor\n",
      "Method: batch\n",
      "Best classifier: GDClassifier(alpha=0.01, learning_rate=0.1, n_iter=2500, type_='batch')\n",
      "Best CV score: 0.7259\n",
      "Test score: 0.6\n",
      "***** ***** ***** *****\n",
      "\n",
      "***** ***** ***** *****\n",
      "Target class: Iris-virginica\n",
      "Method: batch\n",
      "Best classifier: GDClassifier(alpha=0.001, learning_rate=0.1, n_iter=2500, type_='batch')\n",
      "Best CV score: 0.963\n",
      "Test score: 0.8667\n",
      "***** ***** ***** *****\n",
      "\n",
      "***** ***** ***** *****\n",
      "Target class: Iris-setosa\n",
      "Method: stochastic\n",
      "Best classifier: GDClassifier(alpha=0.01, learning_rate=0.1, n_iter=100, type_='stochastic')\n",
      "Best CV score: 1.0\n",
      "Test score: 1.0\n",
      "***** ***** ***** *****\n",
      "\n",
      "***** ***** ***** *****\n",
      "Target class: Iris-versicolor\n",
      "Method: stochastic\n",
      "Best classifier: GDClassifier(alpha=0.0001, learning_rate=0.1, n_iter=750, type_='stochastic')\n",
      "Best CV score: 0.7556\n",
      "Test score: 0.6667\n",
      "***** ***** ***** *****\n",
      "\n",
      "***** ***** ***** *****\n",
      "Target class: Iris-virginica\n",
      "Method: stochastic\n",
      "Best classifier: GDClassifier(alpha=0.001, learning_rate=0.05, n_iter=2500, type_='stochastic')\n",
      "Best CV score: 0.9704\n",
      "Test score: 0.8667\n",
      "***** ***** ***** *****\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for type_ in ['batch', 'stochastic']:\n",
    "    for cls in classes:\n",
    "        print('***** ***** ***** *****')\n",
    "        print(f'Target class: {cls}')\n",
    "        print(f'Method: {type_}')\n",
    "\n",
    "        X_train, y_train = prepare_data(train_data[[0, 1, 2, 3]], train_data[4], cls)\n",
    "        X_test, y_test = prepare_data(test_data[[0, 1, 2, 3]], test_data[4], cls)\n",
    "\n",
    "        kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        clf = GridSearchCV(GDClassifier(type_=type_), param_grid=param_grid, scoring='accuracy', n_jobs=-1, cv=kf)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        print(f'Best classifier: {clf.best_estimator_}')\n",
    "        print(f'Best CV score: {clf.best_score_:.4}')\n",
    "        print(f'Test score: {accuracy_score(y_test, clf.predict(X_test)):.4}')\n",
    "        print('***** ***** ***** *****')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из полученных результатов можно видеть, что хорошо отделимый класс \"Iris-setosa\" классифицируется обоими алгоритмами за наименьшее количество итераций. И на кросс-валидации, и на тестовой выборке алгоритм не ошибся.\n",
    "\n",
    "Для класса \"Iris-versicolor\" результаты не такие радостные. Алгоритму потребовалось больше итераций, чтобы сойтись. При этом SGD справился с задачей за меньшее количество итераций чем BGD.\n",
    "\n",
    "Класс \"Iris-virginica\" алгоритм распознает достаточно хорошо, что видно по результатам и на кросс-валидации, и на тестовой выборке. \n",
    "\n",
    "\n",
    "\n",
    "Обобщив, получим, что и на кросс-валидации, и на тестовой выборке SGD показал немного лучше результаты, чем BGD на всех классах ирисов. Результаты работы обоих алгоритмов сопоставимы.\n",
    "\n",
    "Преимущества SGD:\n",
    "    Требует меньших вычислительных затрат, так как работает только с одним объектом за итерацию.\n",
    "\n",
    "Недостатки SGD:\n",
    "    Может застрять в локальном минимуме.\n",
    "\n",
    "Преимущества BGD:\n",
    "    Стабильная сходимость.\n",
    "\n",
    "Недостатки BGD:\n",
    "    Требует больших вычислительных затрат, так как оперирует всей выборкой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Внесем изменения в класс, чтобы поддерживались оптимизаторы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GDClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, type_='stochastic', learning_rate=0.01, n_iter=1000, alpha=0.01,\n",
    "                 optimization=None, beta=0.9, gamma=0.9, eps=1.0e-9):\n",
    "        self.type_ = type_\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iter = n_iter\n",
    "        self.alpha = alpha\n",
    "\n",
    "        self.weights = None\n",
    "        self.coeffs_ = None\n",
    "\n",
    "        # add optimization\n",
    "        self.optimization = optimization\n",
    "        self.beta = beta\n",
    "        self.gamma = gamma\n",
    "        self.eps = eps\n",
    "\n",
    "        self.func_router = {\n",
    "            'adam': self.adam,\n",
    "            'rmsprop': self.rmsprop,\n",
    "            'adagrad': self.adagrad,\n",
    "            'momentum': self.momentum,\n",
    "            'nesterov_momentum': self.nesterov_momentum\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid(x):\n",
    "        return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_gradient(x, y, w):\n",
    "        grad = np.dot(x.T, GDClassifier.sigmoid(x.dot(w)) - y)\n",
    "        return grad if len(x.shape) == 1 else grad / len(x)\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        x, y = X_train, y_train\n",
    "        n_obs = x.shape[0]\n",
    "        n_features = x.shape[1]\n",
    "\n",
    "        self.weights = np.zeros((self.n_iter, n_features))\n",
    "        u = np.zeros_like(self.weights[0])\n",
    "\n",
    "        for k in range(self.n_iter - 1):\n",
    "            if self.type_ == 'stochastic':\n",
    "                ind = randint(0, n_obs - 1)\n",
    "                x, y = X_train[ind, :], y_train[ind]\n",
    "\n",
    "            w = self.weights[k]\n",
    "\n",
    "            try:\n",
    "                u = self.func_router[self.optimization](x, y, u, w)\n",
    "            except:\n",
    "                raise Exception('Unknown optimization.')\n",
    "\n",
    "            self.weights[k+1] = self.weights[k] + u\n",
    "\n",
    "        half = self.n_iter//2\n",
    "        self.coeffs_ = self.weights[half:].mean(axis=0)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.sigmoid(X.dot(self.coeffs_)) >= 0.5\n",
    "\n",
    "    def adam(self, x, y, u, w):\n",
    "        m = np.zeros_like(self.weights[0])\n",
    "        v = np.zeros_like(self.weights[0])\n",
    "\n",
    "        grad = self.compute_gradient(x, y, w) + self.alpha * w\n",
    "        m = self.gamma * m + (1 - self.gamma) * grad\n",
    "        v = self.beta * v + (1 - self.beta) * (grad ** 2)\n",
    "        return - self.learning_rate * m / (np.sqrt(v) + self.eps)\n",
    "\n",
    "    def rmsprop(self, x, y, u, w):\n",
    "        g = np.zeros_like(self.weights[0])\n",
    "\n",
    "        grad = self.compute_gradient(x, y, w) + self.alpha * w\n",
    "        g = self.beta * g + (1 - self.beta) * (grad ** 2)\n",
    "        return -self.learning_rate * grad / (np.sqrt(g + self.eps))\n",
    "\n",
    "    def adagrad(self, x, y, u, w):\n",
    "        g = np.zeros_like(self.weights[0])\n",
    "\n",
    "        grad = self.compute_gradient(x, y, w) + self.alpha * w\n",
    "        g += grad ** 2\n",
    "        return -self.learning_rate * grad / (np.sqrt(g) + self.eps)\n",
    "\n",
    "    def momentum(self, x, y, u, w):\n",
    "        grad = self.compute_gradient(x, y, w) + self.alpha * w\n",
    "        return self.gamma * u - self.learning_rate * grad\n",
    "\n",
    "    def nesterov_momentum(self, x, y, u, w):\n",
    "        w += self.gamma * u\n",
    "        grad = self.compute_gradient(x, y, w) + self.alpha * w\n",
    "        return self.gamma * u - self.learning_rate * grad\n",
    "\n",
    "    def plot_iterations(self, max_iterations, X_train, y_train, X_test, y_test):\n",
    "        self.n_iter = max_iterations\n",
    "        self.fit(X_train, y_train)\n",
    "\n",
    "        accuracies = [accuracy_score(y_test, self.sigmoid(X_test.dot(self.weights[i//2:].mean(axis=0))) >= 0.5)\n",
    "                      for i in range(1, max_iterations)]\n",
    "\n",
    "        plt.plot(range(1, max_iterations), accuracies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'learning_rate': [0.1, 0.05, 0.01, 0.005, 0.001],\n",
    "    'n_iter': [100, 200, 500, 1000, 2000, 3000, 5000],\n",
    "    'alpha': [0.01, 0.001, 0.0001, 0.0],\n",
    "    'beta': [0.9, 0.99, 0.999],\n",
    "    'gamma': [0.9, 0.99, 0.999]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** ***** ***** *****\n",
      "Target class: Iris-setosa\n",
      "Optimizer: {'type_': 'batch', 'optimization': 'adam'}\n",
      "Best classifier: GDClassifier(alpha=0.01, beta=0.9, eps=1e-09, gamma=0.9, learning_rate=0.1,\n",
      "             n_iter=100, optimization='adam', type_='batch')\n",
      "Best CV score: 1.0\n",
      "Test score: 1.0\n",
      "***** ***** ***** *****\n",
      "\n",
      "***** ***** ***** *****\n",
      "Target class: Iris-setosa\n",
      "Optimizer: {'type_': 'batch', 'optimization': 'rmsprop'}\n",
      "Best classifier: GDClassifier(alpha=0.01, beta=0.9, eps=1e-09, gamma=0.9, learning_rate=0.1,\n",
      "             n_iter=100, optimization='rmsprop', type_='batch')\n",
      "Best CV score: 1.0\n",
      "Test score: 1.0\n",
      "***** ***** ***** *****\n",
      "\n",
      "***** ***** ***** *****\n",
      "Target class: Iris-setosa\n",
      "Optimizer: {'type_': 'batch', 'optimization': 'adagrad'}\n",
      "Best classifier: GDClassifier(alpha=0.01, beta=0.9, eps=1e-09, gamma=0.9, learning_rate=0.1,\n",
      "             n_iter=100, optimization='adagrad', type_='batch')\n",
      "Best CV score: 1.0\n",
      "Test score: 1.0\n",
      "***** ***** ***** *****\n",
      "\n",
      "***** ***** ***** *****\n",
      "Target class: Iris-setosa\n",
      "Optimizer: {'type_': 'stochastic', 'optimization': 'momentum'}\n",
      "Best classifier: GDClassifier(alpha=0.01, beta=0.9, eps=1e-09, gamma=0.9, learning_rate=0.1,\n",
      "             n_iter=100, optimization='momentum', type_='stochastic')\n",
      "Best CV score: 1.0\n",
      "Test score: 1.0\n",
      "***** ***** ***** *****\n",
      "\n",
      "***** ***** ***** *****\n",
      "Target class: Iris-setosa\n",
      "Optimizer: {'type_': 'stochastic', 'optimization': 'nesterov_momentum'}\n",
      "Best classifier: GDClassifier(alpha=0.01, beta=0.9, eps=1e-09, gamma=0.9, learning_rate=0.1,\n",
      "             n_iter=100, optimization='nesterov_momentum', type_='stochastic')\n",
      "Best CV score: 1.0\n",
      "Test score: 1.0\n",
      "***** ***** ***** *****\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** ***** ***** *****\n",
      "Target class: Iris-versicolor\n",
      "Optimizer: {'type_': 'batch', 'optimization': 'adam'}\n",
      "Best classifier: GDClassifier(alpha=0.001, beta=0.99, eps=1e-09, gamma=0.9, learning_rate=0.001,\n",
      "             n_iter=1000, optimization='adam', type_='batch')\n",
      "Best CV score: 0.7407\n",
      "Test score: 0.6667\n",
      "***** ***** ***** *****\n",
      "\n",
      "***** ***** ***** *****\n",
      "Target class: Iris-versicolor\n",
      "Optimizer: {'type_': 'batch', 'optimization': 'rmsprop'}\n",
      "Best classifier: GDClassifier(alpha=0.01, beta=0.99, eps=1e-09, gamma=0.9, learning_rate=0.01,\n",
      "             n_iter=100, optimization='rmsprop', type_='batch')\n",
      "Best CV score: 0.7333\n",
      "Test score: 0.6667\n",
      "***** ***** ***** *****\n",
      "\n",
      "***** ***** ***** *****\n",
      "Target class: Iris-versicolor\n",
      "Optimizer: {'type_': 'batch', 'optimization': 'adagrad'}\n",
      "Best classifier: GDClassifier(alpha=0.001, beta=0.9, eps=1e-09, gamma=0.9, learning_rate=0.001,\n",
      "             n_iter=1000, optimization='adagrad', type_='batch')\n",
      "Best CV score: 0.7407\n",
      "Test score: 0.6667\n",
      "***** ***** ***** *****\n",
      "\n",
      "***** ***** ***** *****\n",
      "Target class: Iris-versicolor\n",
      "Optimizer: {'type_': 'stochastic', 'optimization': 'momentum'}\n",
      "Best classifier: GDClassifier(alpha=0.0001, beta=0.99, eps=1e-09, gamma=0.999, learning_rate=0.1,\n",
      "             n_iter=500, optimization='momentum', type_='stochastic')\n",
      "Best CV score: 0.7778\n",
      "Test score: 0.5333\n",
      "***** ***** ***** *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:28: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** ***** ***** *****\n",
      "Target class: Iris-versicolor\n",
      "Optimizer: {'type_': 'stochastic', 'optimization': 'nesterov_momentum'}\n"
     ]
    }
   ],
   "source": [
    "optimizer = [\n",
    "    {'type_': 'batch', 'optimization': 'adam'},\n",
    "    {'type_': 'batch', 'optimization': 'rmsprop'},\n",
    "    {'type_': 'batch', 'optimization': 'adagrad'},\n",
    "    {'type_': 'stochastic', 'optimization': 'momentum'},\n",
    "    {'type_': 'stochastic', 'optimization': 'nesterov_momentum'},\n",
    "]\n",
    "\n",
    "for cls in classes:\n",
    "    X_train, y_train = prepare_data(train_data[[0, 1, 2, 3]], train_data[4], cls)\n",
    "    X_test, y_test = prepare_data(test_data[[0, 1, 2, 3]], test_data[4], cls)\n",
    "\n",
    "    for opt in optimizer:\n",
    "        print('***** ***** ***** *****')\n",
    "        print(f'Target class: {cls}')\n",
    "        print(f'Optimizer: {opt}')\n",
    "\n",
    "        kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        clf = GridSearchCV(GDClassifier(**opt), param_grid=param_grid, scoring='accuracy', n_jobs=-1, cv=kf)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        print(f'Best classifier: {clf.best_estimator_}')\n",
    "        print(f'Best CV score: {clf.best_score_:.4}')\n",
    "        print(f'Test score: {accuracy_score(y_test, clf.predict(X_test)):.4}')\n",
    "        print('***** ***** ***** *****')\n",
    "        print()\n",
    "\n",
    "        clf.best_estimator_.plot_iterations(1500, X_train, y_train, X_test, y_test)\n",
    "\n",
    "    plt.title(f\"Accuracy for '{cls}' model\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
