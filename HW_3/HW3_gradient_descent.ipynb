{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW3. Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разобъем выборку на тренировочную и тестовую. Разбиение будем проводить сбалансированное, чтобы сохранялось процентное соотношение классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('Iris-setosa', 'Iris-versicolor', 'Iris-virginica')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3            4\n",
       "0  5.1  3.5  1.4  0.2  Iris-setosa\n",
       "1  4.9  3.0  1.4  0.2  Iris-setosa\n",
       "2  4.7  3.2  1.3  0.2  Iris-setosa\n",
       "3  4.6  3.1  1.5  0.2  Iris-setosa\n",
       "4  5.0  3.6  1.4  0.2  Iris-setosa"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('iris.data', header=None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((135, 5), (15, 5))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = train_test_split(data, train_size=0.9, random_state=42, stratify=data[4])\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[[0, 1, 2, 3]]\n",
    "y_train = train[4]\n",
    "X_test = test[[0, 1, 2, 3]]\n",
    "y_test = test[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "train_scaled = pd.DataFrame(scaler.transform(X_train))\n",
    "train_scaled[4] = y_train.reset_index(drop=True)\n",
    "test_scaled = pd.DataFrame(scaler.transform(X_test))\n",
    "test_scaled[4] = y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.937066</td>\n",
       "      <td>-0.348086</td>\n",
       "      <td>0.484926</td>\n",
       "      <td>0.124931</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.328874</td>\n",
       "      <td>-1.029122</td>\n",
       "      <td>1.056673</td>\n",
       "      <td>0.255674</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.815428</td>\n",
       "      <td>-0.121073</td>\n",
       "      <td>0.827974</td>\n",
       "      <td>1.040127</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.279318</td>\n",
       "      <td>-1.256135</td>\n",
       "      <td>0.084703</td>\n",
       "      <td>-0.136553</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.788535</td>\n",
       "      <td>-0.348086</td>\n",
       "      <td>1.456896</td>\n",
       "      <td>0.778642</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.738979</td>\n",
       "      <td>0.332951</td>\n",
       "      <td>-1.401839</td>\n",
       "      <td>-1.313232</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.738979</td>\n",
       "      <td>-0.121073</td>\n",
       "      <td>-1.401839</td>\n",
       "      <td>-1.313232</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.009148</td>\n",
       "      <td>0.786976</td>\n",
       "      <td>-1.287490</td>\n",
       "      <td>-1.313232</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.693789</td>\n",
       "      <td>-0.575098</td>\n",
       "      <td>1.056673</td>\n",
       "      <td>1.301611</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.937066</td>\n",
       "      <td>-0.121073</td>\n",
       "      <td>0.370577</td>\n",
       "      <td>0.255674</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.036041</td>\n",
       "      <td>2.149050</td>\n",
       "      <td>-1.459014</td>\n",
       "      <td>-1.313232</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.815428</td>\n",
       "      <td>-0.121073</td>\n",
       "      <td>0.999499</td>\n",
       "      <td>0.778642</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.693789</td>\n",
       "      <td>0.332951</td>\n",
       "      <td>0.427751</td>\n",
       "      <td>0.386416</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.058705</td>\n",
       "      <td>-0.121073</td>\n",
       "      <td>0.713625</td>\n",
       "      <td>0.647900</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.765871</td>\n",
       "      <td>0.786976</td>\n",
       "      <td>-1.344664</td>\n",
       "      <td>-1.313232</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3                4\n",
       "0   0.937066 -0.348086  0.484926  0.124931  Iris-versicolor\n",
       "1   0.328874 -1.029122  1.056673  0.255674   Iris-virginica\n",
       "2   0.815428 -0.121073  0.827974  1.040127   Iris-virginica\n",
       "3  -0.279318 -1.256135  0.084703 -0.136553  Iris-versicolor\n",
       "4   1.788535 -0.348086  1.456896  0.778642   Iris-virginica\n",
       "5  -1.738979  0.332951 -1.401839 -1.313232      Iris-setosa\n",
       "6  -1.738979 -0.121073 -1.401839 -1.313232      Iris-setosa\n",
       "7  -1.009148  0.786976 -1.287490 -1.313232      Iris-setosa\n",
       "8   0.693789 -0.575098  1.056673  1.301611   Iris-virginica\n",
       "9   0.937066 -0.121073  0.370577  0.255674  Iris-versicolor\n",
       "10 -0.036041  2.149050 -1.459014 -1.313232      Iris-setosa\n",
       "11  0.815428 -0.121073  0.999499  0.778642   Iris-virginica\n",
       "12  0.693789  0.332951  0.427751  0.386416  Iris-versicolor\n",
       "13  1.058705 -0.121073  0.713625  0.647900  Iris-versicolor\n",
       "14 -0.765871  0.786976 -1.344664 -1.313232      Iris-setosa"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled.to_csv('train.csv', header=False, index=False)\n",
    "test_scaled.to_csv('test.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv', header=None)\n",
    "test_data = pd.read_csv('test.csv', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 - 3.\n",
    "Обучите модель логистической регресси с помощью SGD и batch gradient descent. Подберите нужные параметры по сетке. Сравните полученные решения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем свой класс-классификатор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GDClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, type_='stochastic', learning_rate=0.01, n_iter=1000, alpha=0.01):\n",
    "        self.type_ = type_\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iter = n_iter\n",
    "        self.alpha = alpha\n",
    "\n",
    "        self.weights = None\n",
    "        self.coeffs_ = None\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid(x):\n",
    "        return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_gradient(x, y, w):\n",
    "        grad = np.dot(x.T, GDClassifier.sigmoid(x.dot(w)) - y)\n",
    "        return grad if len(x.shape) == 1 else grad / len(x)\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        x, y = X_train, y_train\n",
    "        n_obs = x.shape[0]\n",
    "        n_features = x.shape[1]\n",
    "\n",
    "        self.weights = np.zeros((self.n_iter, n_features))\n",
    "\n",
    "        for k in range(self.n_iter - 1):\n",
    "            if self.type_ == 'stochastic':\n",
    "                ind = randint(0, n_obs - 1)\n",
    "                x, y = X_train[ind, :], y_train[ind]\n",
    "\n",
    "            w = self.weights[k]\n",
    "            grad = self.compute_gradient(x, y, w) + self.alpha*w\n",
    "\n",
    "            u = -self.learning_rate*grad\n",
    "            self.weights[k+1] = self.weights[k] + u\n",
    "        \n",
    "        half = self.n_iter//2\n",
    "        self.coeffs_ = self.weights[half:].mean(axis=0)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.sigmoid(X.dot(self.coeffs_)) >= 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим данные: выберем константный столбец и выделим наш целевой класс в данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(X, y, class_name):\n",
    "    X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "    y = (y == class_name)\n",
    "    return X.astype(float), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зададим данные для перебора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'learning_rate': [0.1, 0.05, 0.01, 0.005, 0.001],\n",
    "    'n_iter': [100, 200, 500, 750, 1000, 2500, 5000],\n",
    "    'alpha': [0.01, 0.001, 0.0001, 0.0]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем эксперименты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** ***** ***** *****\n",
      "Target class: Iris-setosa\n",
      "Method: batch\n",
      "Best classifier: GDClassifier(alpha=0.01, learning_rate=0.1, n_iter=100, type_='batch')\n",
      "Best CV score: 1.0\n",
      "Test score: 1.0\n",
      "***** ***** ***** *****\n",
      "\n",
      "***** ***** ***** *****\n",
      "Target class: Iris-versicolor\n",
      "Method: batch\n",
      "Best classifier: GDClassifier(alpha=0.01, learning_rate=0.1, n_iter=2500, type_='batch')\n",
      "Best CV score: 0.7259\n",
      "Test score: 0.6\n",
      "***** ***** ***** *****\n",
      "\n",
      "***** ***** ***** *****\n",
      "Target class: Iris-virginica\n",
      "Method: batch\n",
      "Best classifier: GDClassifier(alpha=0.001, learning_rate=0.1, n_iter=2500, type_='batch')\n",
      "Best CV score: 0.963\n",
      "Test score: 0.8667\n",
      "***** ***** ***** *****\n",
      "\n",
      "***** ***** ***** *****\n",
      "Target class: Iris-setosa\n",
      "Method: stochastic\n",
      "Best classifier: GDClassifier(alpha=0.01, learning_rate=0.1, n_iter=100, type_='stochastic')\n",
      "Best CV score: 1.0\n",
      "Test score: 1.0\n",
      "***** ***** ***** *****\n",
      "\n",
      "***** ***** ***** *****\n",
      "Target class: Iris-versicolor\n",
      "Method: stochastic\n",
      "Best classifier: GDClassifier(alpha=0.0001, learning_rate=0.1, n_iter=750, type_='stochastic')\n",
      "Best CV score: 0.7556\n",
      "Test score: 0.6667\n",
      "***** ***** ***** *****\n",
      "\n",
      "***** ***** ***** *****\n",
      "Target class: Iris-virginica\n",
      "Method: stochastic\n",
      "Best classifier: GDClassifier(alpha=0.001, learning_rate=0.05, n_iter=2500, type_='stochastic')\n",
      "Best CV score: 0.9704\n",
      "Test score: 0.8667\n",
      "***** ***** ***** *****\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for type_ in ['batch', 'stochastic']:\n",
    "    for cls in classes:\n",
    "        print('***** ***** ***** *****')\n",
    "        print(f'Target class: {cls}')\n",
    "        print(f'Method: {type_}')\n",
    "\n",
    "        X_train, y_train = prepare_data(train_data[[0, 1, 2, 3]], train_data[4], cls)\n",
    "        X_test, y_test = prepare_data(test_data[[0, 1, 2, 3]], test_data[4], cls)\n",
    "\n",
    "        kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        clf = GridSearchCV(GDClassifier(type_=type_), param_grid=param_grid, scoring='accuracy', n_jobs=-1, cv=kf)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        print(f'Best classifier: {clf.best_estimator_}')\n",
    "        print(f'Best CV score: {clf.best_score_:.4}')\n",
    "        print(f'Test score: {accuracy_score(y_test, clf.predict(X_test)):.4}')\n",
    "        print('***** ***** ***** *****')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из полученных результатов можно видеть, что хорошо отделимый класс \"Iris-setosa\" классифицируется обоими алгоритмами за наименьшее количество итераций. И на кросс-валидации, и на тестовой выборке алгоритм не ошибся.\n",
    "\n",
    "Для класса \"Iris-versicolor\" результаты не такие радостные. Алгоритму потребовалось больше итераций, чтобы сойтись. При этом SGD справился с задачей за меньшее количество итераций чем BGD.\n",
    "\n",
    "Класс \"Iris-virginica\" алгоритм распознает достаточно хорошо, что видно по результатам и на кросс-валидации, и на тестовой выборке. \n",
    "\n",
    "\n",
    "\n",
    "Обобщив, получим, что и на кросс-валидации, и на тестовой выборке SGD показал немного лучше результаты, чем BGD на всех классах ирисов. Результаты работы обоих алгоритмов сопоставимы.\n",
    "\n",
    "Преимущества SGD:\n",
    "    Требует меньших вычислительных затрат, так как работает только с одним объектом за итерацию.\n",
    "\n",
    "Недостатки SGD:\n",
    "    Может застрять в локальном минимуме.\n",
    "\n",
    "Преимущества BGD:\n",
    "    Стабильная сходимость.\n",
    "\n",
    "Недостатки BGD:\n",
    "    Требует больших вычислительных затрат, так как оперирует всей выборкой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Внесем изменения в класс, чтобы поддерживались оптимизаторы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GDClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, type_='stochastic', learning_rate=0.01, n_iter=1000, alpha=0.01,\n",
    "                 optimization=None, beta=0.9, gamma=0.9, eps=1.0e-9):\n",
    "        self.type_ = type_\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iter = n_iter\n",
    "        self.alpha = alpha\n",
    "\n",
    "        self.weights = None\n",
    "        self.coeffs_ = None\n",
    "\n",
    "        # add optimization\n",
    "        self.optimization = optimization\n",
    "        self.beta = beta\n",
    "        self.gamma = gamma\n",
    "        self.eps = eps\n",
    "\n",
    "        self.func_router = {\n",
    "            'adam': self.adam,\n",
    "            'rmsprop': self.rmsprop,\n",
    "            'adagrad': self.adagrad,\n",
    "            'momentum': self.momentum,\n",
    "            'nesterov_momentum': self.nesterov_momentum\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid(x):\n",
    "        return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_gradient(x, y, w):\n",
    "        grad = np.dot(x.T, GDClassifier.sigmoid(x.dot(w)) - y)\n",
    "        return grad if len(x.shape) == 1 else grad / len(x)\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        x, y = X_train, y_train\n",
    "        n_obs = x.shape[0]\n",
    "        n_features = x.shape[1]\n",
    "\n",
    "        self.weights = np.zeros((self.n_iter, n_features))\n",
    "        u = np.zeros_like(self.weights[0])\n",
    "\n",
    "        for k in range(self.n_iter - 1):\n",
    "            if self.type_ == 'stochastic':\n",
    "                ind = randint(0, n_obs - 1)\n",
    "                x, y = X_train[ind, :], y_train[ind]\n",
    "\n",
    "            w = self.weights[k]\n",
    "\n",
    "            try:\n",
    "                u = self.func_router[self.optimization](x, y, u, w)\n",
    "            except:\n",
    "                raise Exception('Unknown optimization.')\n",
    "\n",
    "            self.weights[k+1] = self.weights[k] + u\n",
    "\n",
    "        half = self.n_iter//2\n",
    "        self.coeffs_ = self.weights[half:].mean(axis=0)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.sigmoid(X.dot(self.coeffs_)) >= 0.5\n",
    "\n",
    "    def adam(self, x, y, u, w):\n",
    "        m = np.zeros_like(self.weights[0])\n",
    "        v = np.zeros_like(self.weights[0])\n",
    "\n",
    "        grad = self.compute_gradient(x, y, w) + self.alpha * w\n",
    "        m = self.gamma * m + (1 - self.gamma) * grad\n",
    "        v = self.beta * v + (1 - self.beta) * (grad ** 2)\n",
    "        return - self.learning_rate * m / (np.sqrt(v) + self.eps)\n",
    "\n",
    "    def rmsprop(self, x, y, u, w):\n",
    "        g = np.zeros_like(self.weights[0])\n",
    "\n",
    "        grad = self.compute_gradient(x, y, w) + self.alpha * w\n",
    "        g = self.beta * g + (1 - self.beta) * (grad ** 2)\n",
    "        return -self.learning_rate * grad / (np.sqrt(g + self.eps))\n",
    "\n",
    "    def adagrad(self, x, y, u, w):\n",
    "        g = np.zeros_like(self.weights[0])\n",
    "\n",
    "        grad = self.compute_gradient(x, y, w) + self.alpha * w\n",
    "        g += grad ** 2\n",
    "        return -self.learning_rate * grad / (np.sqrt(g) + self.eps)\n",
    "\n",
    "    def momentum(self, x, y, u, w):\n",
    "        grad = self.compute_gradient(x, y, w) + self.alpha * w\n",
    "        return self.gamma * u - self.learning_rate * grad\n",
    "\n",
    "    def nesterov_momentum(self, x, y, u, w):\n",
    "        w += self.gamma * u\n",
    "        grad = self.compute_gradient(x, y, w) + self.alpha * w\n",
    "        return self.gamma * u - self.learning_rate * grad\n",
    "\n",
    "    def plot_iterations(self, max_iterations, X_train, y_train, X_test, y_test):\n",
    "        self.n_iter = max_iterations\n",
    "        self.fit(X_train, y_train)\n",
    "\n",
    "        accuracies = [accuracy_score(y_test, self.sigmoid(X_test.dot(self.weights[i//2:].mean(axis=0))) >= 0.5)\n",
    "                      for i in range(1, max_iterations)]\n",
    "\n",
    "        plt.plot(range(1, max_iterations), accuracies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'learning_rate': [0.1, 0.05, 0.01, 0.005, 0.001],\n",
    "    'n_iter': [100, 200, 500, 1000, 2000, 3000, 5000],\n",
    "    'alpha': [0.01, 0.001, 0.0001, 0.0],\n",
    "    'beta': [0.9, 0.99, 0.999],\n",
    "    'gamma': [0.9, 0.99, 0.999]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** ***** ***** *****\n",
      "Target class: Iris-setosa\n",
      "Optimizer: {'type_': 'batch', 'optimization': 'adam'}\n",
      "Best classifier: GDClassifier(alpha=0.01, beta=0.9, eps=1e-09, gamma=0.9, learning_rate=0.1,\n",
      "             n_iter=100, optimization='adam', type_='batch')\n",
      "Best CV score: 1.0\n",
      "Test score: 1.0\n",
      "***** ***** ***** *****\n",
      "\n",
      "***** ***** ***** *****\n",
      "Target class: Iris-setosa\n",
      "Optimizer: {'type_': 'batch', 'optimization': 'rmsprop'}\n",
      "Best classifier: GDClassifier(alpha=0.01, beta=0.9, eps=1e-09, gamma=0.9, learning_rate=0.1,\n",
      "             n_iter=100, optimization='rmsprop', type_='batch')\n",
      "Best CV score: 1.0\n",
      "Test score: 1.0\n",
      "***** ***** ***** *****\n",
      "\n",
      "***** ***** ***** *****\n",
      "Target class: Iris-setosa\n",
      "Optimizer: {'type_': 'batch', 'optimization': 'adagrad'}\n",
      "Best classifier: GDClassifier(alpha=0.01, beta=0.9, eps=1e-09, gamma=0.9, learning_rate=0.1,\n",
      "             n_iter=100, optimization='adagrad', type_='batch')\n",
      "Best CV score: 1.0\n",
      "Test score: 1.0\n",
      "***** ***** ***** *****\n",
      "\n",
      "***** ***** ***** *****\n",
      "Target class: Iris-setosa\n",
      "Optimizer: {'type_': 'stochastic', 'optimization': 'momentum'}\n",
      "Best classifier: GDClassifier(alpha=0.01, beta=0.9, eps=1e-09, gamma=0.9, learning_rate=0.1,\n",
      "             n_iter=100, optimization='momentum', type_='stochastic')\n",
      "Best CV score: 1.0\n",
      "Test score: 1.0\n",
      "***** ***** ***** *****\n",
      "\n",
      "***** ***** ***** *****\n",
      "Target class: Iris-setosa\n",
      "Optimizer: {'type_': 'stochastic', 'optimization': 'nesterov_momentum'}\n",
      "Best classifier: GDClassifier(alpha=0.01, beta=0.9, eps=1e-09, gamma=0.9, learning_rate=0.1,\n",
      "             n_iter=100, optimization='nesterov_momentum', type_='stochastic')\n",
      "Best CV score: 1.0\n",
      "Test score: 1.0\n",
      "***** ***** ***** *****\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** ***** ***** *****\n",
      "Target class: Iris-versicolor\n",
      "Optimizer: {'type_': 'batch', 'optimization': 'adam'}\n",
      "Best classifier: GDClassifier(alpha=0.001, beta=0.99, eps=1e-09, gamma=0.9, learning_rate=0.001,\n",
      "             n_iter=1000, optimization='adam', type_='batch')\n",
      "Best CV score: 0.7407\n",
      "Test score: 0.6667\n",
      "***** ***** ***** *****\n",
      "\n",
      "***** ***** ***** *****\n",
      "Target class: Iris-versicolor\n",
      "Optimizer: {'type_': 'batch', 'optimization': 'rmsprop'}\n",
      "Best classifier: GDClassifier(alpha=0.01, beta=0.99, eps=1e-09, gamma=0.9, learning_rate=0.01,\n",
      "             n_iter=100, optimization='rmsprop', type_='batch')\n",
      "Best CV score: 0.7333\n",
      "Test score: 0.6667\n",
      "***** ***** ***** *****\n",
      "\n",
      "***** ***** ***** *****\n",
      "Target class: Iris-versicolor\n",
      "Optimizer: {'type_': 'batch', 'optimization': 'adagrad'}\n",
      "Best classifier: GDClassifier(alpha=0.001, beta=0.9, eps=1e-09, gamma=0.9, learning_rate=0.001,\n",
      "             n_iter=1000, optimization='adagrad', type_='batch')\n",
      "Best CV score: 0.7407\n",
      "Test score: 0.6667\n",
      "***** ***** ***** *****\n",
      "\n",
      "***** ***** ***** *****\n",
      "Target class: Iris-versicolor\n",
      "Optimizer: {'type_': 'stochastic', 'optimization': 'momentum'}\n",
      "Best classifier: GDClassifier(alpha=0.0001, beta=0.99, eps=1e-09, gamma=0.999, learning_rate=0.1,\n",
      "             n_iter=500, optimization='momentum', type_='stochastic')\n",
      "Best CV score: 0.7778\n",
      "Test score: 0.5333\n",
      "***** ***** ***** *****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:28: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** ***** ***** *****\n",
      "Target class: Iris-versicolor\n",
      "Optimizer: {'type_': 'stochastic', 'optimization': 'nesterov_momentum'}\n",
      "Best classifier: GDClassifier(alpha=0.0, beta=0.9, eps=1e-09, gamma=0.999, learning_rate=0.05,\n",
      "             n_iter=500, optimization='nesterov_momentum', type_='stochastic')\n",
      "Best CV score: 0.7704\n",
      "Test score: 0.6667\n",
      "***** ***** ***** *****\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** ***** ***** *****\n",
      "Target class: Iris-virginica\n",
      "Optimizer: {'type_': 'batch', 'optimization': 'adam'}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-4e9983a07e78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mkf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGDClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Best classifier: {clf.best_estimator_}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    686\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    665\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 667\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    906\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    552\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    553\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = [\n",
    "    {'type_': 'batch', 'optimization': 'adam'},\n",
    "    {'type_': 'batch', 'optimization': 'rmsprop'},\n",
    "    {'type_': 'batch', 'optimization': 'adagrad'},\n",
    "    {'type_': 'stochastic', 'optimization': 'momentum'},\n",
    "    {'type_': 'stochastic', 'optimization': 'nesterov_momentum'},\n",
    "]\n",
    "\n",
    "for cls in classes:\n",
    "    X_train, y_train = prepare_data(train_data[[0, 1, 2, 3]], train_data[4], cls)\n",
    "    X_test, y_test = prepare_data(test_data[[0, 1, 2, 3]], test_data[4], cls)\n",
    "\n",
    "    for opt in optimizer:\n",
    "        print('***** ***** ***** *****')\n",
    "        print(f'Target class: {cls}')\n",
    "        print(f'Optimizer: {opt}')\n",
    "\n",
    "        kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        clf = GridSearchCV(GDClassifier(**opt), param_grid=param_grid, scoring='accuracy', n_jobs=-1, cv=kf)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        print(f'Best classifier: {clf.best_estimator_}')\n",
    "        print(f'Best CV score: {clf.best_score_:.4}')\n",
    "        print(f'Test score: {accuracy_score(y_test, clf.predict(X_test)):.4}')\n",
    "        print('***** ***** ***** *****')\n",
    "        print()\n",
    "\n",
    "        clf.best_estimator_.plot_iterations(1500, X_train, y_train, X_test, y_test)\n",
    "\n",
    "    plt.title(f\"Accuracy for '{cls}' model\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
